#!/usr/bin/env python3
"""
sLM Foundation Model Training Script

Physical AI ì‹œìŠ¤í…œì„ ìœ„í•œ sLM Foundation Modelì˜ 
í›ˆë ¨ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
"""

import asyncio
import argparse
import logging
import sys
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('slm_training.log'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

async def train_slm_foundation_model(config: dict):
    """sLM Foundation Model í›ˆë ¨ ì‹¤í–‰"""
    
    logger.info("ğŸš€ sLM Foundation Model í›ˆë ¨ ì‹œì‘")
    logger.info(f"ğŸ“‹ ì„¤ì •: {config}")
    
    try:
        # Foundation Model ì´ˆê¸°í™”
        from foundation_model.slm_foundation import SLMFoundation
        
        foundation = SLMFoundation(
            model_type=config.get("model_type", "phi35"),
            model_name=config.get("model_name", "microsoft/Phi-3.5-mini-instruct"),
            device=config.get("device", "auto"),
            learning_config=config.get("learning_config", {}),
            training_output_dir=config.get("training_output_dir", "models/slm_foundation"),
            num_epochs=config.get("num_epochs", 3),
            batch_size=config.get("batch_size", 4),
            learning_rate=config.get("learning_rate", 5e-5)
        )
        
        # ì´ˆê¸°í™”
        logger.info("ğŸ”§ Foundation Model ì´ˆê¸°í™” ì¤‘...")
        await foundation.initialize()
        logger.info("âœ… Foundation Model ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í›ˆë ¨ ë°ì´í„° ìƒì„± (ê¸°ë³¸ ì˜ˆì œë“¤)
        if config.get("generate_training_data", True):
            logger.info("ğŸ“š í›ˆë ¨ ë°ì´í„° ìƒì„± ì¤‘...")
            await generate_training_data(foundation, config)
        
        # ëª¨ë¸ í›ˆë ¨
        logger.info("ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        training_result = await foundation.train_model(
            resume_from_checkpoint=config.get("resume_from_checkpoint", False)
        )
        
        if training_result["success"]:
            logger.info("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
            logger.info(f"ğŸ“Š í›ˆë ¨ ì†ì‹¤: {training_result['training_loss']:.4f}")
            logger.info(f"ğŸ“Š ê²€ì¦ ì†ì‹¤: {training_result['validation_loss']:.4f}")
            logger.info(f"â±ï¸ í›ˆë ¨ ì‹œê°„: {training_result['training_time']:.1f}ì´ˆ")
        else:
            logger.error(f"ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {training_result.get('error', 'Unknown error')}")
            return False
        
        # ëª¨ë¸ í‰ê°€
        if config.get("evaluate_model", True):
            logger.info("ğŸ” ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
            eval_result = await foundation.evaluate_model()
            
            if eval_result["success"]:
                logger.info("âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ")
                logger.info(f"ğŸ“Š ì •í™•ë„: {eval_result['accuracy']:.3f}")
                logger.info(f"ğŸ“Š í‰ê·  ì†ì‹¤: {eval_result['average_loss']:.4f}")
            else:
                logger.warning(f"âš ï¸ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {eval_result.get('error', 'Unknown error')}")
        
        # ëª¨ë¸ ë‚´ë³´ë‚´ê¸°
        if config.get("export_model", True):
            logger.info("ğŸ’¾ ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì¤‘...")
            export_result = await foundation.export_trained_model(
                config.get("export_path", "models/slm_foundation_exported")
            )
            
            if export_result["success"]:
                logger.info("âœ… ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ")
                logger.info(f"ğŸ“ ë‚´ë³´ë‚´ê¸° ê²½ë¡œ: {export_result['export_path']}")
            else:
                logger.warning(f"âš ï¸ ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {export_result.get('error', 'Unknown error')}")
        
        # ìµœì¢… ìƒíƒœ ì¶œë ¥
        final_status = await foundation.get_training_status()
        logger.info("ğŸ“Š ìµœì¢… í›ˆë ¨ ìƒíƒœ:")
        logger.info(f"   - ì´ í›ˆë ¨ ì˜ˆì œ: {final_status.get('total_examples', 0)}ê°œ")
        logger.info(f"   - ê²€ì¦ ì˜ˆì œ: {final_status.get('validation_examples', 0)}ê°œ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ í›ˆë ¨ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return False

async def generate_training_data(foundation, config: dict):
    """í›ˆë ¨ ë°ì´í„° ìƒì„±"""
    
    # ê¸°ë³¸ í›ˆë ¨ ë¯¸ì…˜ë“¤
    training_missions = [
        {
            "mission": "Pick up the red cup and place it on the table",
            "context": {"environment": "simple", "safety_level": "normal"}
        },
        {
            "mission": "Organize the books on the shelf by size",
            "context": {"environment": "complex", "safety_level": "high"}
        },
        {
            "mission": "Clean up the messy desk by putting items in their proper places",
            "context": {"environment": "complex", "safety_level": "normal"}
        },
        {
            "mission": "Help me prepare dinner by bringing ingredients from the pantry",
            "context": {"environment": "simple", "safety_level": "high"}
        },
        {
            "mission": "Assist the elderly person by bringing their medicine and water",
            "context": {"environment": "complex", "safety_level": "high"}
        },
        {
            "mission": "Sort the laundry by color and fabric type",
            "context": {"environment": "simple", "safety_level": "normal"}
        },
        {
            "mission": "Set up the dining table with plates, utensils, and glasses",
            "context": {"environment": "complex", "safety_level": "normal"}
        },
        {
            "mission": "Water the plants in the living room",
            "context": {"environment": "simple", "safety_level": "low"}
        },
        {
            "mission": "Assist in laboratory by preparing chemical solutions",
            "context": {"environment": "laboratory", "safety_level": "critical"}
        },
        {
            "mission": "Help in kitchen by chopping vegetables safely",
            "context": {"environment": "kitchen", "safety_level": "high"}
        }
    ]
    
    logger.info(f"ğŸ“‹ {len(training_missions)}ê°œì˜ ë¯¸ì…˜ìœ¼ë¡œ í›ˆë ¨ ë°ì´í„° ìƒì„±")
    
    for i, mission_data in enumerate(training_missions, 1):
        try:
            logger.info(f"ğŸ“š í›ˆë ¨ ë°ì´í„° {i}/{len(training_missions)}: {mission_data['mission']}")
            
            result = await foundation.process_mission_with_learning(
                mission=mission_data['mission'],
                context=mission_data['context']
            )
            
            if result['success']:
                logger.info(f"   âœ… í•™ìŠµ ê°€ì¹˜: {result['learning_value']:.3f}")
            else:
                logger.warning(f"   âš ï¸ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
        
        except Exception as e:
            logger.error(f"   âŒ ì˜¤ë¥˜: {e}")
        
        # ì ì‹œ ëŒ€ê¸°
        await asyncio.sleep(0.1)

def load_config(config_path: str = None) -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    
    default_config = {
        "model_type": "phi35",
        "model_name": "microsoft/Phi-3.5-mini-instruct",
        "device": "auto",
        "learning_config": {
            "enabled": True,
            "learning_rate": 0.01,
            "min_confidence_threshold": 0.7,
            "max_examples": 1000,
            "pattern_update_interval": 10,
            "adaptation_threshold": 0.6
        },
        "training_output_dir": "models/slm_foundation",
        "num_epochs": 3,
        "batch_size": 4,
        "learning_rate": 5e-5,
        "generate_training_data": True,
        "evaluate_model": True,
        "export_model": True,
        "resume_from_checkpoint": False
    }
    
    if config_path and Path(config_path).exists():
        import json
        with open(config_path, 'r') as f:
            user_config = json.load(f)
        default_config.update(user_config)
        logger.info(f"ğŸ“„ ì„¤ì • íŒŒì¼ ë¡œë“œë¨: {config_path}")
    
    return default_config

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    parser = argparse.ArgumentParser(description="sLM Foundation Model í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--config", type=str, help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--model-type", type=str, default="phi35", help="ëª¨ë¸ íƒ€ì…")
    parser.add_argument("--model-name", type=str, help="ëª¨ë¸ ì´ë¦„")
    parser.add_argument("--device", type=str, default="auto", help="ë””ë°”ì´ìŠ¤ (auto/cpu/cuda)")
    parser.add_argument("--epochs", type=int, default=3, help="í›ˆë ¨ ì—í¬í¬ ìˆ˜")
    parser.add_argument("--batch-size", type=int, default=4, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--learning-rate", type=float, default=5e-5, help="í•™ìŠµë¥ ")
    parser.add_argument("--output-dir", type=str, default="models/slm_foundation", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--resume", action="store_true", help="ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ")
    parser.add_argument("--no-eval", action="store_true", help="ëª¨ë¸ í‰ê°€ ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--no-export", action="store_true", help="ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--no-data-gen", action="store_true", help="í›ˆë ¨ ë°ì´í„° ìƒì„± ê±´ë„ˆë›°ê¸°")
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = load_config(args.config)
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì„¤ì • ë®ì–´ì“°ê¸°
    if args.model_type:
        config["model_type"] = args.model_type
    if args.model_name:
        config["model_name"] = args.model_name
    if args.device:
        config["device"] = args.device
    if args.epochs:
        config["num_epochs"] = args.epochs
    if args.batch_size:
        config["batch_size"] = args.batch_size
    if args.learning_rate:
        config["learning_rate"] = args.learning_rate
    if args.output_dir:
        config["training_output_dir"] = args.output_dir
    if args.resume:
        config["resume_from_checkpoint"] = True
    if args.no_eval:
        config["evaluate_model"] = False
    if args.no_export:
        config["export_model"] = False
    if args.no_data_gen:
        config["generate_training_data"] = False
    
    # í›ˆë ¨ ì‹¤í–‰
    success = asyncio.run(train_slm_foundation_model(config))
    
    if success:
        logger.info("sLM Foundation Model í›ˆë ¨ ì™„ë£Œ!")
        sys.exit(0)
    else:
        logger.error("sLM Foundation Model í›ˆë ¨ ì‹¤íŒ¨!")
        sys.exit(1)

if __name__ == "__main__":
    main()
