"""
sLM Foundation Model Training Module - ëª¨ë¸ í›ˆë ¨ ë° íŒŒì¸íŠœë‹

Physical AI ì‹œìŠ¤í…œì„ ìœ„í•œ sLM Foundation Modelì˜ 
í›ˆë ¨, íŒŒì¸íŠœë‹, ì„±ëŠ¥ í‰ê°€ë¥¼ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
"""

import asyncio
import json
import torch
import numpy as np
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
import pickle
import hashlib
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AutoTokenizer, 
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)

logger = logging.getLogger(__name__)

@dataclass
class TrainingConfig:
    """í›ˆë ¨ ì„¤ì •"""
    model_name: str = "microsoft/Phi-3.5-mini-instruct"
    output_dir: str = "models/slm_foundation"
    num_epochs: int = 3
    batch_size: int = 4
    learning_rate: float = 5e-5
    warmup_steps: int = 100
    weight_decay: float = 0.01
    gradient_accumulation_steps: int = 4
    max_grad_norm: float = 1.0
    logging_steps: int = 10
    save_steps: int = 500
    eval_steps: int = 100
    save_total_limit: int = 3
    fp16: bool = True
    dataloader_pin_memory: bool = False

@dataclass
class TrainingExample:
    """í›ˆë ¨ ì˜ˆì œ"""
    mission: str
    context: Dict[str, Any]
    subtasks: List[Dict[str, Any]]
    constraints: Dict[str, Any]
    success_criteria: List[str]
    execution_result: Dict[str, Any]
    learning_value: float

class PhysicalAIDataset(Dataset):
    """Physical AI í›ˆë ¨ ë°ì´í„°ì…‹"""
    
    def __init__(self, examples: List[TrainingExample], tokenizer, max_length: int = 512):
        self.examples = examples
        self.tokenizer = tokenizer
        self.max_length = max_length
        
    def __len__(self):
        return len(self.examples)
    
    def __getitem__(self, idx):
        example = self.examples[idx]
        
        # ì…ë ¥ í…ìŠ¤íŠ¸ êµ¬ì„±
        input_text = self._format_input(example)
        
        # í† í¬ë‚˜ì´ì§•
        encoding = self.tokenizer(
            input_text,
            truncation=True,
            max_length=self.max_length,
            padding="max_length",
            return_tensors="pt"
        )
        
        return {
            "input_ids": encoding["input_ids"].squeeze(),
            "attention_mask": encoding["attention_mask"].squeeze(),
            "labels": encoding["input_ids"].squeeze()
        }
    
    def _format_input(self, example: TrainingExample) -> str:
        """ì…ë ¥ í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
        context_str = ", ".join([f"{k}: {v}" for k, v in example.context.items()])
        subtasks_str = "\n".join([f"- {task['action']}: {task.get('target', '')}" 
                                 for task in example.subtasks])
        constraints_str = ", ".join([f"{k}: {v}" for k, v in example.constraints.items()])
        
        input_text = f"""Mission: {example.mission}
Context: {context_str}
Subtasks:
{subtasks_str}
Constraints: {constraints_str}
Success Criteria: {', '.join(example.success_criteria)}
Execution Result: {example.execution_result.get('success', False)}
Learning Value: {example.learning_value:.3f}"""
        
        return input_text

class SLMTrainingModule:
    """sLM Foundation Model í›ˆë ¨ ëª¨ë“ˆ"""
    
    def __init__(self, 
                 phi35_manager,
                 training_config: TrainingConfig = None):
        self.phi35_manager = phi35_manager
        self.config = training_config or TrainingConfig()
        
        # í›ˆë ¨ ë°ì´í„°
        self.training_examples: List[TrainingExample] = []
        self.validation_examples: List[TrainingExample] = []
        
        # í›ˆë ¨ ìƒíƒœ
        self.is_training = False
        self.current_epoch = 0
        self.global_step = 0
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.training_metrics = {
            "total_examples": 0,
            "training_loss": [],
            "validation_loss": [],
            "learning_rate": [],
            "best_validation_loss": float('inf'),
            "training_time": 0.0
        }
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.output_dir = Path(self.config.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info("ğŸ§  sLM Foundation Model í›ˆë ¨ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize(self):
        """í›ˆë ¨ ëª¨ë“ˆ ì´ˆê¸°í™”"""
        logger.info("ğŸš€ sLM Foundation Model í›ˆë ¨ ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘...")
        
        # ê¸°ì¡´ í›ˆë ¨ ë°ì´í„° ë¡œë“œ
        await self._load_training_data()
        
        # í›ˆë ¨ ë°ì´í„° ê²€ì¦
        await self._validate_training_data()
        
        logger.info("âœ… sLM Foundation Model í›ˆë ¨ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def _load_training_data(self):
        """ê¸°ì¡´ í›ˆë ¨ ë°ì´í„° ë¡œë“œ"""
        try:
            # í›ˆë ¨ ì˜ˆì œ ë¡œë“œ
            training_file = self.output_dir / "training_examples.pkl"
            if training_file.exists():
                with open(training_file, 'rb') as f:
                    self.training_examples = pickle.load(f)
                logger.info(f"ğŸ“š {len(self.training_examples)}ê°œ í›ˆë ¨ ì˜ˆì œ ë¡œë“œë¨")
            
            # ê²€ì¦ ì˜ˆì œ ë¡œë“œ
            validation_file = self.output_dir / "validation_examples.pkl"
            if validation_file.exists():
                with open(validation_file, 'rb') as f:
                    self.validation_examples = pickle.load(f)
                logger.info(f"ğŸ“š {len(self.validation_examples)}ê°œ ê²€ì¦ ì˜ˆì œ ë¡œë“œë¨")
                
        except Exception as e:
            logger.warning(f"âš ï¸ í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    async def _validate_training_data(self):
        """í›ˆë ¨ ë°ì´í„° ê²€ì¦"""
        if not self.training_examples:
            logger.warning("âš ï¸ í›ˆë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì˜ˆì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            await self._generate_basic_examples()
        
        if not self.validation_examples:
            logger.warning("âš ï¸ ê²€ì¦ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í›ˆë ¨ ë°ì´í„°ì—ì„œ ë¶„í• í•©ë‹ˆë‹¤.")
            await self._split_validation_data()
    
    async def _generate_basic_examples(self):
        """ê¸°ë³¸ í›ˆë ¨ ì˜ˆì œ ìƒì„±"""
        basic_examples = [
            TrainingExample(
                mission="Pick up the red cup and place it on the table",
                context={"environment": "simple", "safety_level": "normal"},
                subtasks=[
                    {"action": "move_to", "target": "cup_location"},
                    {"action": "grasp", "target": "red_cup"},
                    {"action": "move_to", "target": "table_location"},
                    {"action": "place", "target": "table"}
                ],
                constraints={"max_force": 50.0, "safety_distance": 0.1},
                success_criteria=["cup_picked", "cup_placed"],
                execution_result={"success": True, "efficiency": 0.8},
                learning_value=0.7
            ),
            TrainingExample(
                mission="Organize books on the shelf by size",
                context={"environment": "complex", "safety_level": "high"},
                subtasks=[
                    {"action": "explore", "target": "bookshelf"},
                    {"action": "grasp", "target": "small_book"},
                    {"action": "place", "target": "small_section"},
                    {"action": "grasp", "target": "large_book"},
                    {"action": "place", "target": "large_section"}
                ],
                constraints={"max_force": 30.0, "safety_distance": 0.2},
                success_criteria=["books_organized", "shelf_neat"],
                execution_result={"success": True, "efficiency": 0.6},
                learning_value=0.8
            ),
            TrainingExample(
                mission="Clean up the desk by putting items in their proper places",
                context={"environment": "complex", "safety_level": "normal"},
                subtasks=[
                    {"action": "explore", "target": "desk_surface"},
                    {"action": "grasp", "target": "pencil"},
                    {"action": "place", "target": "pencil_holder"},
                    {"action": "grasp", "target": "paper"},
                    {"action": "place", "target": "paper_tray"}
                ],
                constraints={"max_force": 20.0, "safety_distance": 0.1},
                success_criteria=["desk_clean", "items_organized"],
                execution_result={"success": True, "efficiency": 0.7},
                learning_value=0.6
            )
        ]
        
        self.training_examples.extend(basic_examples)
        logger.info(f"ğŸ“š {len(basic_examples)}ê°œ ê¸°ë³¸ í›ˆë ¨ ì˜ˆì œ ìƒì„±ë¨")
    
    async def _split_validation_data(self):
        """ê²€ì¦ ë°ì´í„° ë¶„í• """
        if len(self.training_examples) < 2:
            return
        
        # 20%ë¥¼ ê²€ì¦ ë°ì´í„°ë¡œ ë¶„í• 
        split_idx = int(len(self.training_examples) * 0.8)
        self.validation_examples = self.training_examples[split_idx:]
        self.training_examples = self.training_examples[:split_idx]
        
        logger.info(f"ğŸ“š í›ˆë ¨: {len(self.training_examples)}ê°œ, ê²€ì¦: {len(self.validation_examples)}ê°œ")
    
    async def add_training_example(self, example: TrainingExample, is_validation: bool = False):
        """í›ˆë ¨ ì˜ˆì œ ì¶”ê°€"""
        if is_validation:
            self.validation_examples.append(example)
        else:
            self.training_examples.append(example)
        
        self.training_metrics["total_examples"] += 1
        
        # ë°ì´í„° ì €ì¥
        await self._save_training_data()
        
        logger.info(f"í›ˆë ¨ ì˜ˆì œ ì¶”ê°€ë¨ ({'ê²€ì¦' if is_validation else 'í›ˆë ¨'})")
    
    async def _save_training_data(self):
        """í›ˆë ¨ ë°ì´í„° ì €ì¥"""
        try:
            # í›ˆë ¨ ì˜ˆì œ ì €ì¥
            training_file = self.output_dir / "training_examples.pkl"
            with open(training_file, 'wb') as f:
                pickle.dump(self.training_examples, f)
            
            # ê²€ì¦ ì˜ˆì œ ì €ì¥
            validation_file = self.output_dir / "validation_examples.pkl"
            with open(validation_file, 'wb') as f:
                pickle.dump(self.validation_examples, f)
                
        except Exception as e:
            logger.error(f"âŒ í›ˆë ¨ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def prepare_training_data(self) -> Tuple[Dataset, Dataset]:
        """í›ˆë ¨ ë°ì´í„° ì¤€ë¹„"""
        if not self.phi35_manager or not self.phi35_manager.tokenizer:
            raise Exception("PHI-3.5 ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = PhysicalAIDataset(
            self.training_examples,
            self.phi35_manager.tokenizer,
            max_length=512
        )
        
        # ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±
        val_dataset = PhysicalAIDataset(
            self.validation_examples,
            self.phi35_manager.tokenizer,
            max_length=512
        )
        
        logger.info(f"í›ˆë ¨ ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ: {len(train_dataset)}ê°œ, ê²€ì¦: {len(val_dataset)}ê°œ")
        
        return train_dataset, val_dataset
    
    async def train_model(self, resume_from_checkpoint: bool = False) -> Dict[str, Any]:
        """ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰"""
        if self.is_training:
            raise Exception("ì´ë¯¸ í›ˆë ¨ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.")
        
        logger.info("sLM Foundation Model í›ˆë ¨ ì‹œì‘")
        self.is_training = True
        start_time = datetime.now()
        
        try:
            # 1. ë°ì´í„° ì¤€ë¹„
            train_dataset, val_dataset = await self.prepare_training_data()
            
            # 2. í›ˆë ¨ ì„¤ì •
            training_args = TrainingArguments(
                output_dir=str(self.output_dir),
                num_train_epochs=self.config.num_epochs,
                per_device_train_batch_size=self.config.batch_size,
                per_device_eval_batch_size=self.config.batch_size,
                learning_rate=self.config.learning_rate,
                warmup_steps=self.config.warmup_steps,
                weight_decay=self.config.weight_decay,
                gradient_accumulation_steps=self.config.gradient_accumulation_steps,
                max_grad_norm=self.config.max_grad_norm,
                logging_steps=self.config.logging_steps,
                save_steps=self.config.save_steps,
                eval_steps=self.config.eval_steps,
                save_total_limit=self.config.save_total_limit,
                fp16=self.config.fp16,
                dataloader_pin_memory=self.config.dataloader_pin_memory,
                # evaluation_strategy="steps",  # ì´ì „ ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬
                load_best_model_at_end=True,
                metric_for_best_model="eval_loss",
                greater_is_better=False,
                report_to=None  # wandb ë¹„í™œì„±í™”
            )
            
            # 3. ë°ì´í„° ì½œë ˆì´í„°
            data_collator = DataCollatorForLanguageModeling(
                tokenizer=self.phi35_manager.tokenizer,
                mlm=False
            )
            
            # 4. íŠ¸ë ˆì´ë„ˆ ìƒì„±
            trainer = Trainer(
                model=self.phi35_manager.model,
                args=training_args,
                train_dataset=train_dataset,
                eval_dataset=val_dataset,
                data_collator=data_collator,
                tokenizer=self.phi35_manager.tokenizer
            )
            
            # 5. í›ˆë ¨ ì‹¤í–‰
            logger.info("ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
            train_result = trainer.train(resume_from_checkpoint=resume_from_checkpoint)
            
            # 6. ê²€ì¦
            logger.info("ëª¨ë¸ ê²€ì¦ ì¤‘...")
            eval_result = trainer.evaluate()
            
            # 7. ëª¨ë¸ ì €ì¥
            logger.info("ëª¨ë¸ ì €ì¥ ì¤‘...")
            trainer.save_model()
            trainer.save_state()
            
            # 8. í›ˆë ¨ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            training_time = (datetime.now() - start_time).total_seconds()
            self.training_metrics.update({
                "training_loss": train_result.training_loss,
                "validation_loss": eval_result["eval_loss"],
                "training_time": training_time,
                "best_validation_loss": min(self.training_metrics["best_validation_loss"], 
                                          eval_result["eval_loss"])
            })
            
            # 9. í›ˆë ¨ ê²°ê³¼ ì €ì¥
            await self._save_training_results(train_result, eval_result)
            
            logger.info("sLM Foundation Model í›ˆë ¨ ì™„ë£Œ")
            
            return {
                "success": True,
                "training_loss": train_result.training_loss,
                "validation_loss": eval_result["eval_loss"],
                "training_time": training_time,
                "model_path": str(self.output_dir)
            }
            
        except Exception as e:
            logger.error(f"í›ˆë ¨ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e)
            }
        
        finally:
            self.is_training = False
    
    async def _save_training_results(self, train_result, eval_result):
        """í›ˆë ¨ ê²°ê³¼ ì €ì¥"""
        results = {
            "training_metrics": self.training_metrics,
            "train_result": {
                "training_loss": train_result.training_loss,
                "global_step": train_result.global_step,
                "epoch": train_result.epoch
            },
            "eval_result": eval_result,
            "timestamp": datetime.now().isoformat()
        }
        
        results_file = self.output_dir / "training_results.json"
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
    
    async def evaluate_model(self, test_examples: List[TrainingExample] = None) -> Dict[str, Any]:
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        if not test_examples:
            test_examples = self.validation_examples
        
        if not test_examples:
            return {"success": False, "error": "í‰ê°€í•  ì˜ˆì œê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        logger.info(f"ğŸ” ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘: {len(test_examples)}ê°œ ì˜ˆì œ")
        
        try:
            total_loss = 0.0
            correct_predictions = 0
            total_predictions = 0
            
            for example in test_examples:
                # ëª¨ë¸ ì˜ˆì¸¡
                prediction = await self._predict_example(example)
                
                # ì •í™•ë„ ê³„ì‚° (ê°„ë‹¨í•œ êµ¬í˜„)
                if prediction.get("success") == example.execution_result.get("success"):
                    correct_predictions += 1
                total_predictions += 1
                
                # ì†ì‹¤ ê³„ì‚° (ê°„ë‹¨í•œ êµ¬í˜„)
                predicted_value = prediction.get("learning_value", 0.0)
                actual_value = example.learning_value
                loss = abs(predicted_value - actual_value)
                total_loss += loss
            
            accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0
            avg_loss = total_loss / len(test_examples) if test_examples else 0.0
            
            evaluation_results = {
                "success": True,
                "accuracy": accuracy,
                "average_loss": avg_loss,
                "total_examples": len(test_examples),
                "correct_predictions": correct_predictions
            }
            
            logger.info(f"ğŸ“Š í‰ê°€ ê²°ê³¼: ì •í™•ë„ {accuracy:.3f}, í‰ê·  ì†ì‹¤ {avg_loss:.3f}")
            
            return evaluation_results
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    async def _predict_example(self, example: TrainingExample) -> Dict[str, Any]:
        """ë‹¨ì¼ ì˜ˆì œ ì˜ˆì¸¡"""
        try:
            # ì…ë ¥ í…ìŠ¤íŠ¸ êµ¬ì„±
            input_text = self._format_input_for_prediction(example)
            
            # í† í¬ë‚˜ì´ì§•
            inputs = self.phi35_manager.tokenizer(
                input_text,
                return_tensors="pt",
                truncation=True,
                max_length=512
            )
            
            # ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.phi35_manager.model(**inputs)
                logits = outputs.logits
            
            # ê²°ê³¼ í•´ì„ (ê°„ë‹¨í•œ êµ¬í˜„)
            prediction = {
                "success": True,  # ê¸°ë³¸ê°’
                "learning_value": 0.5,  # ê¸°ë³¸ê°’
                "confidence": 0.7  # ê¸°ë³¸ê°’
            }
            
            return prediction
            
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def _format_input_for_prediction(self, example: TrainingExample) -> str:
        """ì˜ˆì¸¡ìš© ì…ë ¥ í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
        context_str = ", ".join([f"{k}: {v}" for k, v in example.context.items()])
        subtasks_str = "\n".join([f"- {task['action']}: {task.get('target', '')}" 
                                 for task in example.subtasks])
        
        input_text = f"""Mission: {example.mission}
Context: {context_str}
Subtasks:
{subtasks_str}
Constraints: {example.constraints}
Success Criteria: {example.success_criteria}

Predict the execution result and learning value:"""
        
        return input_text
    
    async def get_training_status(self) -> Dict[str, Any]:
        """í›ˆë ¨ ìƒíƒœ ì¡°íšŒ"""
        return {
            "is_training": self.is_training,
            "current_epoch": self.current_epoch,
            "global_step": self.global_step,
            "training_metrics": self.training_metrics,
            "total_examples": len(self.training_examples),
            "validation_examples": len(self.validation_examples)
        }
    
    async def export_model(self, export_path: str = None) -> Dict[str, Any]:
        """í›ˆë ¨ëœ ëª¨ë¸ ë‚´ë³´ë‚´ê¸°"""
        if not export_path:
            export_path = self.output_dir / "exported_model"
        
        try:
            # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥
            self.phi35_manager.model.save_pretrained(export_path)
            self.phi35_manager.tokenizer.save_pretrained(export_path)
            
            # ì„¤ì • íŒŒì¼ ì €ì¥
            config = {
                "model_name": self.config.model_name,
                "training_config": asdict(self.config),
                "training_metrics": self.training_metrics,
                "export_timestamp": datetime.now().isoformat()
            }
            
            config_file = Path(export_path) / "config.json"
            with open(config_file, 'w') as f:
                json.dump(config, f, indent=2, default=str)
            
            logger.info(f"âœ… ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {export_path}")
            
            return {
                "success": True,
                "export_path": str(export_path),
                "config": config
            }
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    async def test_training_module():
        """í›ˆë ¨ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸"""
        print("ğŸ§  sLM Foundation Model í›ˆë ¨ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
        
        # PHI-3.5 ë§¤ë‹ˆì € ìƒì„± (ëª¨ì˜)
        class MockPHI35Manager:
            def __init__(self):
                self.tokenizer = None
                self.model = None
        
        phi35_manager = MockPHI35Manager()
        
        # í›ˆë ¨ ëª¨ë“ˆ ì´ˆê¸°í™”
        training_module = SLMTrainingModule(phi35_manager)
        await training_module.initialize()
        
        # í›ˆë ¨ ìƒíƒœ ì¡°íšŒ
        status = await training_module.get_training_status()
        print(f"í›ˆë ¨ ìƒíƒœ: {status}")
        
        print("âœ… í›ˆë ¨ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    asyncio.run(test_training_module())
