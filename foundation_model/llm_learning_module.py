"""
LLM Foundation Learning Module - ê³ ê¸‰ í•™ìŠµ ì‹œìŠ¤í…œ

PHI-3.5 ê¸°ë°˜ Physical AI ì‹œìŠ¤í…œì˜ ê³ ê¸‰ í•™ìŠµ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
ì§€ì†ì  í•™ìŠµ, ì ì‘ì  ì¶”ë¡ , ì§€ì‹ ì¦ê°• ë“±ì„ í†µí•´ ì‹œìŠ¤í…œì´ ì ì§„ì ìœ¼ë¡œ ê°œì„ ë©ë‹ˆë‹¤.
"""

import asyncio
import json
import numpy as np
import torch
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
import pickle
import hashlib

from .phi35_integration import PHI35ModelManager

logger = logging.getLogger(__name__)

@dataclass
class LearningExample:
    """í•™ìŠµ ì˜ˆì œ ë°ì´í„° êµ¬ì¡°"""
    input_mission: str
    context: Dict[str, Any]
    generated_plan: Dict[str, Any]
    execution_result: Dict[str, Any]
    success: bool
    performance_metrics: Dict[str, float]
    timestamp: datetime
    learning_value: float

@dataclass
class KnowledgePattern:
    """ì§€ì‹ íŒ¨í„´ êµ¬ì¡°"""
    pattern_id: str
    pattern_type: str  # "mission_pattern", "motion_pattern", "constraint_pattern"
    pattern_data: Dict[str, Any]
    confidence: float
    usage_count: int
    last_used: datetime
    created_at: datetime

@dataclass
class AdaptationMetrics:
    """ì ì‘ ë©”íŠ¸ë¦­ êµ¬ì¡°"""
    accuracy_improvement: float
    response_time_improvement: float
    success_rate_improvement: float
    knowledge_growth: float
    adaptation_score: float

class LLMLearningModule:
    """LLM Foundation í•™ìŠµ ëª¨ë“ˆ"""
    
    def __init__(self, 
                 phi35_manager: PHI35ModelManager,
                 learning_config: Dict[str, Any]):
        self.phi35_manager = phi35_manager
        self.config = learning_config
        
        # í•™ìŠµ ë°ì´í„° ì €ì¥ì†Œ
        self.learning_examples: List[LearningExample] = []
        self.knowledge_patterns: Dict[str, KnowledgePattern] = {}
        self.adaptation_history: List[AdaptationMetrics] = []
        
        # í•™ìŠµ ìƒíƒœ
        self.is_learning_enabled = True
        self.learning_rate = 0.01
        self.min_confidence_threshold = 0.7
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.performance_metrics = {
            "total_examples": 0,
            "successful_adaptations": 0,
            "knowledge_patterns_created": 0,
            "average_learning_value": 0.0,
            "last_adaptation_time": None
        }
        
        # í•™ìŠµ ë°ì´í„° ì €ì¥ ê²½ë¡œ
        self.data_dir = Path("data/llm_learning")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info("ğŸ§  LLM Foundation í•™ìŠµ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize(self):
        """í•™ìŠµ ëª¨ë“ˆ ì´ˆê¸°í™”"""
        logger.info("ğŸš€ LLM Foundation í•™ìŠµ ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘...")
        
        # ê¸°ì¡´ í•™ìŠµ ë°ì´í„° ë¡œë“œ
        await self._load_learning_data()
        
        # ì§€ì‹ íŒ¨í„´ ì´ˆê¸°í™”
        await self._initialize_knowledge_patterns()
        
        # ì ì‘ ë©”íŠ¸ë¦­ ê³„ì‚°
        await self._calculate_adaptation_metrics()
        
        logger.info("âœ… LLM Foundation í•™ìŠµ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def _load_learning_data(self):
        """ê¸°ì¡´ í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
        try:
            # í•™ìŠµ ì˜ˆì œ ë¡œë“œ
            examples_file = self.data_dir / "learning_examples.pkl"
            if examples_file.exists():
                with open(examples_file, 'rb') as f:
                    self.learning_examples = pickle.load(f)
                logger.info(f"ğŸ“š {len(self.learning_examples)}ê°œ í•™ìŠµ ì˜ˆì œ ë¡œë“œë¨")
            
            # ì§€ì‹ íŒ¨í„´ ë¡œë“œ
            patterns_file = self.data_dir / "knowledge_patterns.pkl"
            if patterns_file.exists():
                with open(patterns_file, 'rb') as f:
                    self.knowledge_patterns = pickle.load(f)
                logger.info(f"ğŸ§© {len(self.knowledge_patterns)}ê°œ ì§€ì‹ íŒ¨í„´ ë¡œë“œë¨")
                
        except Exception as e:
            logger.warning(f"âš ï¸ í•™ìŠµ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    async def _initialize_knowledge_patterns(self):
        """ê¸°ë³¸ ì§€ì‹ íŒ¨í„´ ì´ˆê¸°í™”"""
        if not self.knowledge_patterns:
            # ê¸°ë³¸ ë¬¼ë¦¬ íŒ¨í„´
            basic_patterns = [
                {
                    "pattern_id": "physics_gravity",
                    "pattern_type": "constraint_pattern",
                    "pattern_data": {
                        "constraint": "gravity_effect",
                        "description": "ì¤‘ë ¥ì˜ ì˜í–¥ì„ ê³ ë ¤í•œ ë™ì‘ ê³„íš",
                        "applicable_missions": ["pick", "place", "move"],
                        "physics_rule": "gravity = 9.81 m/sÂ²"
                    },
                    "confidence": 0.95,
                    "usage_count": 0
                },
                {
                    "pattern_id": "safety_distance",
                    "pattern_type": "constraint_pattern", 
                    "pattern_data": {
                        "constraint": "safety_margin",
                        "description": "ì•ˆì „ ê±°ë¦¬ ìœ ì§€",
                        "applicable_missions": ["all"],
                        "safety_rule": "minimum_distance = 0.1m"
                    },
                    "confidence": 0.9,
                    "usage_count": 0
                },
                {
                    "pattern_id": "grasp_sequence",
                    "pattern_type": "motion_pattern",
                    "pattern_data": {
                        "sequence": ["approach", "grasp", "lift", "move", "place"],
                        "description": "ê¸°ë³¸ ì¡ê¸° ë™ì‘ ì‹œí€€ìŠ¤",
                        "applicable_missions": ["pick_and_place"],
                        "energy_optimization": True
                    },
                    "confidence": 0.85,
                    "usage_count": 0
                }
            ]
            
            for pattern_data in basic_patterns:
                pattern = KnowledgePattern(
                    pattern_id=pattern_data["pattern_id"],
                    pattern_type=pattern_data["pattern_type"],
                    pattern_data=pattern_data["pattern_data"],
                    confidence=pattern_data["confidence"],
                    usage_count=pattern_data["usage_count"],
                    last_used=datetime.now(),
                    created_at=datetime.now()
                )
                self.knowledge_patterns[pattern.pattern_id] = pattern
            
            logger.info(f"ğŸ§© {len(basic_patterns)}ê°œ ê¸°ë³¸ ì§€ì‹ íŒ¨í„´ ìƒì„±ë¨")
    
    async def learn_from_experience(self, 
                                  mission: str,
                                  context: Dict[str, Any],
                                  generated_plan: Dict[str, Any],
                                  execution_result: Dict[str, Any]) -> float:
        """ê²½í—˜ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        if not self.is_learning_enabled:
            return 0.0
        
        try:
            # í•™ìŠµ ì˜ˆì œ ìƒì„±
            learning_value = self._calculate_learning_value(execution_result)
            
            example = LearningExample(
                input_mission=mission,
                context=context,
                generated_plan=generated_plan,
                execution_result=execution_result,
                success=execution_result.get("success", False),
                performance_metrics=execution_result.get("performance_metrics", {}),
                timestamp=datetime.now(),
                learning_value=learning_value
            )
            
            # í•™ìŠµ ì˜ˆì œ ì €ì¥
            self.learning_examples.append(example)
            self.performance_metrics["total_examples"] += 1
            
            # ì§€ì‹ íŒ¨í„´ ì—…ë°ì´íŠ¸
            await self._update_knowledge_patterns(example)
            
            # ì ì‘ì  í•™ìŠµ ìˆ˜í–‰
            adaptation_score = await self._perform_adaptive_learning(example)
            
            # í•™ìŠµ ë°ì´í„° ì €ì¥
            await self._save_learning_data()
            
            logger.info(f"ğŸ“š í•™ìŠµ ì™„ë£Œ: í•™ìŠµê°€ì¹˜={learning_value:.3f}, ì ì‘ì ìˆ˜={adaptation_score:.3f}")
            return learning_value
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0.0
    
    def _calculate_learning_value(self, execution_result: Dict[str, Any]) -> float:
        """í•™ìŠµ ê°€ì¹˜ ê³„ì‚°"""
        success = execution_result.get("success", False)
        performance = execution_result.get("performance_metrics", {})
        
        # ê¸°ë³¸ í•™ìŠµ ê°€ì¹˜
        base_value = 1.0 if success else 0.3
        
        # ì„±ëŠ¥ ê¸°ë°˜ ë³´ë„ˆìŠ¤
        efficiency = performance.get("efficiency", 0.5)
        accuracy = performance.get("accuracy", 0.5)
        safety = performance.get("safety_score", 0.5)
        
        # ì¢…í•© í•™ìŠµ ê°€ì¹˜
        learning_value = base_value * (0.4 + 0.2 * efficiency + 0.2 * accuracy + 0.2 * safety)
        
        return min(learning_value, 1.0)  # ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ
    
    async def _update_knowledge_patterns(self, example: LearningExample):
        """ì§€ì‹ íŒ¨í„´ ì—…ë°ì´íŠ¸"""
        try:
            # ë¯¸ì…˜ íŒ¨í„´ ë¶„ì„
            mission_pattern = self._extract_mission_pattern(example.input_mission)
            if mission_pattern:
                await self._update_or_create_pattern("mission_pattern", mission_pattern, example)
            
            # ë™ì‘ íŒ¨í„´ ë¶„ì„
            motion_pattern = self._extract_motion_pattern(example.generated_plan)
            if motion_pattern:
                await self._update_or_create_pattern("motion_pattern", motion_pattern, example)
            
            # ì œì•½ íŒ¨í„´ ë¶„ì„
            constraint_pattern = self._extract_constraint_pattern(example.context, example.execution_result)
            if constraint_pattern:
                await self._update_or_create_pattern("constraint_pattern", constraint_pattern, example)
                
        except Exception as e:
            logger.error(f"âŒ ì§€ì‹ íŒ¨í„´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _extract_mission_pattern(self, mission: str) -> Optional[Dict[str, Any]]:
        """ë¯¸ì…˜ì—ì„œ íŒ¨í„´ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ íŒ¨í„´ ì¶”ì¶œ
        keywords = mission.lower().split()
        
        pattern = {
            "action_type": None,
            "object_type": None,
            "location_type": None,
            "complexity": "simple"
        }
        
        # ì•¡ì…˜ íƒ€ì… ì¶”ì¶œ
        action_keywords = {
            "pick": ["pick", "grab", "take", "lift"],
            "place": ["place", "put", "set", "drop"],
            "move": ["move", "carry", "transport"],
            "organize": ["organize", "arrange", "sort"],
            "clean": ["clean", "wipe", "sweep"]
        }
        
        for action_type, keywords_list in action_keywords.items():
            if any(keyword in keywords for keyword in keywords_list):
                pattern["action_type"] = action_type
                break
        
        # ê°ì²´ íƒ€ì… ì¶”ì¶œ
        object_keywords = ["cup", "book", "box", "tool", "item", "object"]
        for keyword in object_keywords:
            if keyword in keywords:
                pattern["object_type"] = keyword
                break
        
        # ë³µì¡ì„± í‰ê°€
        if len(keywords) > 8 or "and" in keywords:
            pattern["complexity"] = "complex"
        
        return pattern if pattern["action_type"] else None
    
    def _extract_motion_pattern(self, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ë™ì‘ ê³„íšì—ì„œ íŒ¨í„´ ì¶”ì¶œ"""
        subtasks = plan.get("subtasks", [])
        
        if not subtasks:
            return None
        
        pattern = {
            "sequence_length": len(subtasks),
            "motion_types": [],
            "energy_optimization": False,
            "safety_considerations": []
        }
        
        for subtask in subtasks:
            motion_type = subtask.get("type", "unknown")
            pattern["motion_types"].append(motion_type)
            
            # ì—ë„ˆì§€ ìµœì í™” í™•ì¸
            if subtask.get("energy_efficient", False):
                pattern["energy_optimization"] = True
            
            # ì•ˆì „ ê³ ë ¤ì‚¬í•­ í™•ì¸
            safety = subtask.get("safety_checks", [])
            pattern["safety_considerations"].extend(safety)
        
        return pattern
    
    def _extract_constraint_pattern(self, context: Dict[str, Any], result: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ì œì•½ ì¡°ê±´ì—ì„œ íŒ¨í„´ ì¶”ì¶œ"""
        constraints = context.get("constraints", {})
        
        if not constraints:
            return None
        
        pattern = {
            "constraint_types": [],
            "safety_level": "normal",
            "physical_limits": {},
            "environmental_factors": []
        }
        
        # ì œì•½ íƒ€ì… ì¶”ì¶œ
        for constraint_type, value in constraints.items():
            pattern["constraint_types"].append(constraint_type)
            
            if constraint_type == "safety_distance":
                pattern["safety_level"] = "high" if value > 0.2 else "normal"
            elif constraint_type == "max_force":
                pattern["physical_limits"]["max_force"] = value
            elif constraint_type == "environment":
                pattern["environmental_factors"].append(value)
        
        return pattern
    
    async def _update_or_create_pattern(self, pattern_type: str, pattern_data: Dict[str, Any], example: LearningExample):
        """íŒ¨í„´ ì—…ë°ì´íŠ¸ ë˜ëŠ” ìƒì„±"""
        # íŒ¨í„´ ID ìƒì„±
        pattern_hash = hashlib.md5(json.dumps(pattern_data, sort_keys=True).encode()).hexdigest()[:8]
        pattern_id = f"{pattern_type}_{pattern_hash}"
        
        if pattern_id in self.knowledge_patterns:
            # ê¸°ì¡´ íŒ¨í„´ ì—…ë°ì´íŠ¸
            pattern = self.knowledge_patterns[pattern_id]
            pattern.usage_count += 1
            pattern.last_used = datetime.now()
            
            # ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸ (ì„±ê³µí•œ ì˜ˆì œë¡œë¶€í„°)
            if example.success:
                pattern.confidence = min(pattern.confidence + 0.01, 1.0)
            else:
                pattern.confidence = max(pattern.confidence - 0.005, 0.1)
                
        else:
            # ìƒˆ íŒ¨í„´ ìƒì„±
            pattern = KnowledgePattern(
                pattern_id=pattern_id,
                pattern_type=pattern_type,
                pattern_data=pattern_data,
                confidence=0.7 if example.success else 0.3,
                usage_count=1,
                last_used=datetime.now(),
                created_at=datetime.now()
            )
            self.knowledge_patterns[pattern_id] = pattern
            self.performance_metrics["knowledge_patterns_created"] += 1
    
    async def _perform_adaptive_learning(self, example: LearningExample) -> float:
        """ì ì‘ì  í•™ìŠµ ìˆ˜í–‰"""
        try:
            # ìœ ì‚¬í•œ ì˜ˆì œë“¤ ì°¾ê¸°
            similar_examples = self._find_similar_examples(example)
            
            if not similar_examples:
                return 0.0
            
            # íŒ¨í„´ ê¸°ë°˜ ê°œì„ 
            improvements = []
            
            for similar_example in similar_examples:
                # ì„±ê³µ íŒ¨í„´ ë¶„ì„
                if similar_example.success and not example.success:
                    improvement = self._analyze_success_pattern(similar_example, example)
                    improvements.append(improvement)
                
                # ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
                elif not similar_example.success and example.success:
                    improvement = self._analyze_improvement_pattern(similar_example, example)
                    improvements.append(improvement)
            
            # í‰ê·  ê°œì„ ë„ ê³„ì‚°
            adaptation_score = np.mean(improvements) if improvements else 0.0
            
            # ì ì‘ ë©”íŠ¸ë¦­ ê¸°ë¡
            adaptation_metric = AdaptationMetrics(
                accuracy_improvement=adaptation_score,
                response_time_improvement=0.0,  # ì¶”í›„ êµ¬í˜„
                success_rate_improvement=0.0,   # ì¶”í›„ êµ¬í˜„
                knowledge_growth=len(self.knowledge_patterns) / 100.0,
                adaptation_score=adaptation_score
            )
            
            self.adaptation_history.append(adaptation_metric)
            self.performance_metrics["successful_adaptations"] += 1
            self.performance_metrics["last_adaptation_time"] = datetime.now()
            
            return adaptation_score
            
        except Exception as e:
            logger.error(f"âŒ ì ì‘ì  í•™ìŠµ ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _find_similar_examples(self, example: LearningExample, max_examples: int = 5) -> List[LearningExample]:
        """ìœ ì‚¬í•œ ì˜ˆì œë“¤ ì°¾ê¸°"""
        similar_examples = []
        
        for prev_example in reversed(self.learning_examples[:-1]):  # í˜„ì¬ ì˜ˆì œ ì œì™¸
            similarity = self._calculate_similarity(example, prev_example)
            
            if similarity > 0.6:  # ìœ ì‚¬ë„ ì„ê³„ê°’
                similar_examples.append(prev_example)
                
                if len(similar_examples) >= max_examples:
                    break
        
        return similar_examples
    
    def _calculate_similarity(self, example1: LearningExample, example2: LearningExample) -> float:
        """ë‘ ì˜ˆì œ ê°„ ìœ ì‚¬ë„ ê³„ì‚°"""
        # ë¯¸ì…˜ ìœ ì‚¬ë„
        mission_similarity = self._calculate_text_similarity(
            example1.input_mission, example2.input_mission
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
        context_similarity = self._calculate_context_similarity(
            example1.context, example2.context
        )
        
        # ê°€ì¤‘ í‰ê· 
        similarity = 0.6 * mission_similarity + 0.4 * context_similarity
        return similarity
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ êµ¬í˜„)"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union)
    
    def _calculate_context_similarity(self, context1: Dict[str, Any], context2: Dict[str, Any]) -> float:
        """ì»¨í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        # ê°„ë‹¨í•œ í‚¤ ê¸°ë°˜ ìœ ì‚¬ë„
        keys1 = set(context1.keys())
        keys2 = set(context2.keys())
        
        if not keys1 or not keys2:
            return 0.0
        
        intersection = keys1.intersection(keys2)
        union = keys1.union(keys2)
        
        return len(intersection) / len(union)
    
    def _analyze_success_pattern(self, success_example: LearningExample, current_example: LearningExample) -> float:
        """ì„±ê³µ íŒ¨í„´ ë¶„ì„"""
        # ì„±ê³µí•œ ì˜ˆì œì˜ íŠ¹ì§• ë¶„ì„
        success_features = self._extract_success_features(success_example)
        current_features = self._extract_success_features(current_example)
        
        # ì°¨ì´ì  ë¶„ì„
        differences = self._analyze_differences(success_features, current_features)
        
        # ê°œì„  ê°€ëŠ¥ì„± ì ìˆ˜
        improvement_score = sum(differences.values()) / len(differences) if differences else 0.0
        
        return improvement_score
    
    def _analyze_improvement_pattern(self, failure_example: LearningExample, current_example: LearningExample) -> float:
        """ê°œì„  íŒ¨í„´ ë¶„ì„"""
        # ì‹¤íŒ¨í•œ ì˜ˆì œì™€ í˜„ì¬ ì„±ê³µí•œ ì˜ˆì œì˜ ì°¨ì´ì  ë¶„ì„
        failure_features = self._extract_success_features(failure_example)
        current_features = self._extract_success_features(current_example)
        
        # ê°œì„ ëœ ì ë“¤ ë¶„ì„
        improvements = self._analyze_improvements(failure_features, current_features)
        
        # ê°œì„  ì ìˆ˜
        improvement_score = sum(improvements.values()) / len(improvements) if improvements else 0.0
        
        return improvement_score
    
    def _extract_success_features(self, example: LearningExample) -> Dict[str, Any]:
        """ì„±ê³µ íŠ¹ì§• ì¶”ì¶œ"""
        features = {
            "mission_complexity": len(example.input_mission.split()),
            "plan_steps": len(example.generated_plan.get("subtasks", [])),
            "execution_time": example.execution_result.get("execution_time", 0.0),
            "energy_efficiency": example.performance_metrics.get("efficiency", 0.0),
            "safety_score": example.performance_metrics.get("safety_score", 0.0)
        }
        return features
    
    def _analyze_differences(self, features1: Dict[str, Any], features2: Dict[str, Any]) -> Dict[str, float]:
        """íŠ¹ì§• ì°¨ì´ì  ë¶„ì„"""
        differences = {}
        
        for key in features1.keys():
            if key in features2:
                diff = abs(features1[key] - features2[key])
                max_val = max(features1[key], features2[key])
                if max_val > 0:
                    differences[key] = diff / max_val
                else:
                    differences[key] = 0.0
        
        return differences
    
    def _analyze_improvements(self, old_features: Dict[str, Any], new_features: Dict[str, Any]) -> Dict[str, float]:
        """ê°œì„ ì  ë¶„ì„"""
        improvements = {}
        
        for key in old_features.keys():
            if key in new_features:
                if key in ["energy_efficiency", "safety_score"]:
                    # ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ì§€í‘œ
                    improvement = (new_features[key] - old_features[key]) / max(old_features[key], 0.1)
                else:
                    # ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ì§€í‘œ (ì‹œê°„, ë³µì¡ì„± ë“±)
                    improvement = (old_features[key] - new_features[key]) / max(old_features[key], 0.1)
                
                improvements[key] = max(improvement, 0.0)
        
        return improvements
    
    async def _calculate_adaptation_metrics(self):
        """ì ì‘ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if len(self.adaptation_history) < 2:
            return
        
        recent_metrics = self.adaptation_history[-10:]  # ìµœê·¼ 10ê°œ
        
        avg_adaptation = np.mean([m.adaptation_score for m in recent_metrics])
        avg_knowledge_growth = np.mean([m.knowledge_growth for m in recent_metrics])
        
        logger.info(f"ğŸ“Š ì ì‘ ë©”íŠ¸ë¦­ - í‰ê·  ì ì‘ì ìˆ˜: {avg_adaptation:.3f}, ì§€ì‹ì„±ì¥: {avg_knowledge_growth:.3f}")
    
    async def _save_learning_data(self):
        """í•™ìŠµ ë°ì´í„° ì €ì¥"""
        try:
            # í•™ìŠµ ì˜ˆì œ ì €ì¥
            examples_file = self.data_dir / "learning_examples.pkl"
            with open(examples_file, 'wb') as f:
                pickle.dump(self.learning_examples, f)
            
            # ì§€ì‹ íŒ¨í„´ ì €ì¥
            patterns_file = self.data_dir / "knowledge_patterns.pkl"
            with open(patterns_file, 'wb') as f:
                pickle.dump(self.knowledge_patterns, f)
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥
            metrics_file = self.data_dir / "performance_metrics.json"
            with open(metrics_file, 'w') as f:
                json.dump(self.performance_metrics, f, default=str, indent=2)
                
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def get_learning_insights(self) -> Dict[str, Any]:
        """í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì œê³µ"""
        insights = {
            "total_examples": self.performance_metrics["total_examples"],
            "knowledge_patterns": len(self.knowledge_patterns),
            "successful_adaptations": self.performance_metrics["successful_adaptations"],
            "average_learning_value": self.performance_metrics["average_learning_value"],
            "recent_performance": self._get_recent_performance(),
            "top_patterns": self._get_top_patterns(),
            "learning_trends": self._get_learning_trends()
        }
        
        return insights
    
    def _get_recent_performance(self) -> Dict[str, float]:
        """ìµœê·¼ ì„±ëŠ¥ ë¶„ì„"""
        if not self.learning_examples:
            return {}
        
        recent_examples = self.learning_examples[-20:]  # ìµœê·¼ 20ê°œ
        
        success_rate = sum(1 for ex in recent_examples if ex.success) / len(recent_examples)
        avg_learning_value = np.mean([ex.learning_value for ex in recent_examples])
        
        return {
            "success_rate": success_rate,
            "average_learning_value": avg_learning_value,
            "examples_count": len(recent_examples)
        }
    
    def _get_top_patterns(self) -> List[Dict[str, Any]]:
        """ìƒìœ„ íŒ¨í„´ë“¤ ë°˜í™˜"""
        sorted_patterns = sorted(
            self.knowledge_patterns.values(),
            key=lambda p: (p.confidence, p.usage_count),
            reverse=True
        )
        
        top_patterns = []
        for pattern in sorted_patterns[:5]:  # ìƒìœ„ 5ê°œ
            top_patterns.append({
                "pattern_id": pattern.pattern_id,
                "type": pattern.pattern_type,
                "confidence": pattern.confidence,
                "usage_count": pattern.usage_count,
                "description": pattern.pattern_data.get("description", "No description")
            })
        
        return top_patterns
    
    def _get_learning_trends(self) -> Dict[str, Any]:
        """í•™ìŠµ íŠ¸ë Œë“œ ë¶„ì„"""
        if len(self.learning_examples) < 10:
            return {}
        
        # ì‹œê°„ë³„ ì„±ê³µë¥  íŠ¸ë Œë“œ
        recent_examples = self.learning_examples[-50:]  # ìµœê·¼ 50ê°œ
        
        success_trend = []
        learning_value_trend = []
        
        for i in range(0, len(recent_examples), 10):
            batch = recent_examples[i:i+10]
            if batch:
                success_rate = sum(1 for ex in batch if ex.success) / len(batch)
                avg_learning_value = np.mean([ex.learning_value for ex in batch])
                
                success_trend.append(success_rate)
                learning_value_trend.append(avg_learning_value)
        
        return {
            "success_trend": success_trend,
            "learning_value_trend": learning_value_trend,
            "trend_direction": "improving" if success_trend[-1] > success_trend[0] else "declining"
        }
    
    async def optimize_learning_strategy(self) -> Dict[str, Any]:
        """í•™ìŠµ ì „ëµ ìµœì í™”"""
        insights = await self.get_learning_insights()
        
        # ìµœì í™” ì œì•ˆ
        recommendations = []
        
        # ì„±ê³µë¥ ì´ ë‚®ì€ ê²½ìš°
        if insights["recent_performance"]["success_rate"] < 0.6:
            recommendations.append({
                "type": "success_rate_improvement",
                "description": "ì„±ê³µë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. ë” ë§ì€ ê¸°ë³¸ íŒ¨í„´ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "action": "increase_basic_pattern_learning"
            })
        
        # í•™ìŠµ ê°€ì¹˜ê°€ ë‚®ì€ ê²½ìš°
        if insights["recent_performance"]["average_learning_value"] < 0.5:
            recommendations.append({
                "type": "learning_value_improvement", 
                "description": "í•™ìŠµ ê°€ì¹˜ê°€ ë‚®ìŠµë‹ˆë‹¤. ë” ë³µì¡í•œ ë¯¸ì…˜ì— ë„ì „í•´ë³´ì„¸ìš”.",
                "action": "increase_mission_complexity"
            })
        
        # íŒ¨í„´ì´ ë¶€ì¡±í•œ ê²½ìš°
        if insights["knowledge_patterns"] < 10:
            recommendations.append({
                "type": "pattern_diversity",
                "description": "ì§€ì‹ íŒ¨í„´ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë¯¸ì…˜ì„ ì‹œë„í•´ë³´ì„¸ìš”.",
                "action": "increase_mission_variety"
            })
        
        return {
            "insights": insights,
            "recommendations": recommendations,
            "optimization_score": len(recommendations) / 3.0  # ìµœì í™” í•„ìš”ë„
        }
